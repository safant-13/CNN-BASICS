{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kmd_mvr1s7_q",
        "EonnF-357Ajl"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports required for training the model"
      ],
      "metadata": {
        "id": "CY_S6p5-jDbB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NN2ugzpjiY1i"
      },
      "outputs": [],
      "source": [
        "import numpy as np                    # For maths, arrays, image manipulation\n",
        "import matplotlib.pyplot as plt       # To visualize doodles/images\n",
        "import json                           # For reading .ndjson/raw data files\n",
        "import tensorflow as tf               # For deep learning (CNN)\n",
        "import os                             # File system access - finding/loading files\n",
        "from sklearn.model_selection import train_test_split   # For splitting data sets\n",
        "from tensorflow.keras import layers, models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here is the sample dataset!\n",
        "Example for cat"
      ],
      "metadata": {
        "id": "_8sb1hNXjRT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download one category (e.g. 'cat') as example\n",
        "!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy"
      ],
      "metadata": {
        "id": "14b1GNEzjQ76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_images = np.load('cat.npy')\n",
        "print(\"Cat image array shape:\", cat_images.shape)  # Should be (num_samples, 784)\n",
        "print(cat_images[:30])\n",
        "\n",
        "# Visualize\n",
        "plt.imshow(cat_images[0].reshape(28,28), cmap='gray')\n",
        "plt.title(\"Example QuickDraw Cat\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2IdjjLnBjbzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data - prep\n",
        "We’ll train on 10 categories for speed"
      ],
      "metadata": {
        "id": "_RJkNYcgldC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = [\"cat\", \"dog\", \"tree\", \"car\", \"cloud\",\n",
        "              \"house\", \"star\", \"airplane\", \"rainbow\", \"chair\"]\n",
        "\n",
        "# Map category names to numbers\n",
        "label_map = {cat: idx for idx, cat in enumerate(categories)}\n",
        "print(label_map)"
      ],
      "metadata": {
        "id": "9q_V-px0lnRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download & Load"
      ],
      "metadata": {
        "id": "ebV1g-K6l2kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "for category in categories:\n",
        "    url = f\"https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{category}.npy\"\n",
        "    filename = f\"{category}.npy\"\n",
        "\n",
        "    # Download only if not already there\n",
        "    if not os.path.exists(filename):\n",
        "        !wget $url -O $filename\n",
        "\n",
        "    # Load numpy array\n",
        "    images = np.load(filename)\n",
        "\n",
        "    # Normalize pixel values [0,255] → [0,1]\n",
        "    images = images.astype(\"float32\") / 255.0\n",
        "\n",
        "    # Limit samples for speed\n",
        "    n_samples = 10000\n",
        "    all_images.append(images[:n_samples])\n",
        "    all_labels.append(np.full(n_samples, label_map[category]))\n",
        "\n",
        "    print(f\"{category}: {images.shape[0]} total, using {n_samples}\")\n"
      ],
      "metadata": {
        "id": "7CfBcDPOl35O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine and reshape"
      ],
      "metadata": {
        "id": "aVADucRQmNAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine into one dataset\n",
        "X = np.concatenate(all_images, axis=0)\n",
        "y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "print(\"Final dataset shape:\", X.shape, y.shape)\n",
        "\n",
        "# Reshape to (28,28,1) for CNN input\n",
        "X = X.reshape(-1, 28, 28, 1)\n",
        "\n",
        "print(\"Reshaped dataset:\", X.shape)\n"
      ],
      "metadata": {
        "id": "zqnVP6htmPzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Test Split"
      ],
      "metadata": {
        "id": "OMsgGTPbmfJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train/test (stratify = keep class balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train set:\", X_train.shape, y_train.shape)\n",
        "print(\"Test set:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "id": "l9bWmJlcmha3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize Dataset"
      ],
      "metadata": {
        "id": "TiWTK_r7mvgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick 25 random samples to visualize\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    idx = np.random.randint(0, len(X))\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.imshow(X[idx].reshape(28, 28), cmap=\"gray\")\n",
        "    plt.title(categories[y[idx]])\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kpO-hka-mwPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic CNN Model"
      ],
      "metadata": {
        "id": "IEjIrOJKnjNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define CNN with 3 convolutional layers\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(28,28,1)), #learns edges, lines, corners (low-level features).\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), activation=\"relu\"), #combines them into shapes/patterns (loops, strokes).\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), activation=\"relu\"), #more abstract features (e.g. “cat ear”, “wheel”, “star point”).\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(len(categories), activation=\"softmax\")  # output layer\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xOyox4Ywnl6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning + data augumentation"
      ],
      "metadata": {
        "id": "kmd_mvr1s7_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.applications import MobileNetV2\n",
        "# from tensorflow.keras import layers, models\n",
        "\n",
        "# X_train_rgb = tf.image.grayscale_to_rgb(tf.constant(X_train)).numpy()\n",
        "# X_test_rgb = tf.image.grayscale_to_rgb(tf.constant(X_test)).numpy()\n",
        "\n",
        "# IMG_SIZE = 75\n",
        "# X_train_resized = tf.image.resize(X_train_rgb, (IMG_SIZE, IMG_SIZE)).numpy()\n",
        "# X_test_resized = tf.image.resize(X_test_rgb, (IMG_SIZE, IMG_SIZE)).numpy()\n",
        "\n",
        "# print(\"Original training data shape:\", X_train.shape)\n",
        "# print(\"New resized training data shape:\", X_train_resized.shape)\n",
        "# print(\"-\" * 30)\n",
        "\n",
        "\n",
        "# # --- 2. Build the Transfer Learning Model ---\n",
        "\n",
        "# base_model = MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "#                          include_top=False,\n",
        "#                          weights='imagenet')\n",
        "\n",
        "# # Freeze the convolutional base to prevent its weights from changing during training.\n",
        "# base_model.trainable = False\n",
        "\n",
        "# transfer_model = models.Sequential([\n",
        "#     base_model,\n",
        "#     layers.GlobalAveragePooling2D(),\n",
        "#     layers.Dense(128, activation='relu'),\n",
        "#     layers.Dropout(0.3),\n",
        "#     layers.Dense(len(categories), activation='softmax')  # Our output layer\n",
        "# ])\n",
        "\n",
        "# # Compile the model.\n",
        "# transfer_model.compile(optimizer=\"adam\",\n",
        "#                        loss=\"sparse_categorical_crossentropy\",\n",
        "#                        metrics=[\"accuracy\"])\n",
        "\n",
        "# transfer_model.summary()"
      ],
      "metadata": {
        "id": "Ocm7Y0Y5svj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This can be used to augument the image data addded to the model.fit!\n",
        "\n",
        "\n",
        "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# # Create an ImageDataGenerator for data augmentation\n",
        "# datagen = ImageDataGenerator(\n",
        "#     rotation_range=15,\n",
        "#     width_shift_range=0.1,\n",
        "#     height_shift_range=0.1,\n",
        "#     shear_range=0.1,\n",
        "#     zoom_range=0.1,\n",
        "#     horizontal_flip=False, # Not always useful for doodles, but good to know\n",
        "#     fill_mode='nearest'\n",
        "# )"
      ],
      "metadata": {
        "id": "4xy-OCXV5e0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "ZL6zT7M4n8FU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,               # enough to see improvement but not too long in class\n",
        "    batch_size=128,          # process 128 doodles at a time\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n",
        "\n",
        "# Transfer learning\n",
        "\n",
        "# history = transfer_model.fit(\n",
        "#     datagen.flow(X_train, y_train, batch_size=128), # transfer learning  + data augumentation!\n",
        "#     epochs=20,\n",
        "#     validation_data=(X_test_resized, y_test)\n",
        "# )\n",
        "\n",
        "# Plot accuracy and loss over time\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label=\"Train Accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Accuracy Over Time\")\n",
        "plt.legend()\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label=\"Train Loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Model Loss Over Time\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "shsvOz7cn9_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate & Test Predictions"
      ],
      "metadata": {
        "id": "v64kEZtFoThN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "class_names = categories\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
        "\n",
        "# Make predictions on a few random samples\n",
        "import random\n",
        "\n",
        "# Pick 5 random test images\n",
        "indices = random.sample(range(len(X_test)), 5)\n",
        "\n",
        "plt.figure(figsize=(12,3))\n",
        "for i, idx in enumerate(indices):\n",
        "    img = X_test[idx].reshape(28,28)\n",
        "    label = y_test[idx]\n",
        "    pred = np.argmax(model.predict(X_test[idx].reshape(1,28,28,1)))\n",
        "\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f\"Pred: {class_names[pred]}\\nTrue: {class_names[label]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LJLG_Y_0oUHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Testing live"
      ],
      "metadata": {
        "id": "EonnF-357Ajl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def predict_doodle(img):\n",
        "    if img is None:\n",
        "        return \"Please draw something!\"\n",
        "    # If input is dict, use 'composite' image\n",
        "    if isinstance(img, dict):\n",
        "        img = img.get(\"composite\", None)\n",
        "    if img is None:\n",
        "        return \"Please draw something!\"\n",
        "    # Convert the composite PIL Image to grayscale numpy array (already L mode)\n",
        "    img = np.array(img)\n",
        "    # Resize to 28x28 and normalize\n",
        "    img = tf.image.resize(img[..., np.newaxis], (28, 28)).numpy()\n",
        "    img = img / 255.0\n",
        "    # Predict probabilities once\n",
        "    preds = model.predict(img.reshape(1, 28, 28, 1))[0]\n",
        "    # Return label with highest probability\n",
        "    pred_label = class_names[np.argmax(preds)]\n",
        "    return pred_label\n",
        "\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=predict_doodle,\n",
        "    inputs=gr.Sketchpad(type=\"pil\", image_mode=\"L\"),\n",
        "    outputs=\"label\",\n",
        "    live=True,\n",
        ")\n",
        "interface.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "-Qw-3fHfo6W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export the model"
      ],
      "metadata": {
        "id": "rUPTO8yY6l6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H5 model export for general reusablity"
      ],
      "metadata": {
        "id": "JEjYc7_DcbMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "trained_model = model\n",
        "\n",
        "# 1. Define the filename for your model.\n",
        "model_filename = \"doodle_classifier.h5\"\n",
        "\n",
        "# 2. Save the model to the specified file.\n",
        "trained_model.save(model_filename)\n",
        "\n",
        "print(f\"Model successfully saved to '{model_filename}'\")\n",
        "print(\"Starting download...\")\n",
        "\n",
        "# 3. Trigger the download of the file to your local machine.\n",
        "files.download(model_filename)"
      ],
      "metadata": {
        "id": "HyHBmZvGbBjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tf lite export for mobile apps!"
      ],
      "metadata": {
        "id": "9ReUOD1-64YD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a TFLiteConverter object from the Keras model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "# Optimizee\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# 3. Convert the model.\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# 4. Save the converted model to a .tflite file.\n",
        "with open('doodle_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Successfully converted model to 'doodle_model.tflite'\")\n",
        "print(f\"File size: {len(tflite_model) / 1024:.2f} KB\")\n",
        "\n",
        "# 5. Download the file from Colab to your local machine.\n",
        "from google.colab import files\n",
        "files.download('doodle_model.tflite')"
      ],
      "metadata": {
        "id": "9eFHSt_c6lr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tf js export for web apps"
      ],
      "metadata": {
        "id": "vibErJQY7Mop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs\n",
        "\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "# Define the path where you want to save the model\n",
        "output_path = 'doodle_model_js'\n",
        "\n",
        "# Convert the Keras model (use 'model' or 'transfer_model')\n",
        "tfjs.converters.save_keras_model(model, output_path)\n",
        "\n",
        "print(f\"Model saved for TensorFlow.js in the '{output_path}' directory.\")\n",
        "\n",
        "# To download, first zip the directory, then download the zip file.\n",
        "!zip -r {output_path}.zip {output_path}\n",
        "\n",
        "from google.colab import files\n",
        "files.download(f'{output_path}.zip')\n",
        "\n",
        "# NOTE: It creates a directory named doodle_model_js containing a model.json file (the model architecture) and several .bin files (the weights) these bin are named like shards.smtg1.bin, etc."
      ],
      "metadata": {
        "id": "824zvlMQ7Zmk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}